{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd5f1d39-2310-42ae-9477-4cde497374cc",
   "metadata": {},
   "source": [
    "## Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4e2b81-0e10-4390-a7b8-5ddfda53a3e3",
   "metadata": {},
   "source": [
    "### Requirements and Imports\n",
    "\n",
    "Import necessary libraries, including `langchain_core`, `langgraph`, and `langchain_community`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03127548-960c-4565-9648-6137eea0010b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain langchain_core langchain_community langgraph langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf493b9-622f-49dc-a81b-768dabc5139e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Agentic AI libraries\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import VLLMOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "from langchain_core.messages import HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b950bc-4d73-49e5-a35b-083a784edd50",
   "metadata": {},
   "source": [
    "### Tool for checking externally the app\n",
    "\n",
    "Define the tools that the agent will use, such as a simulated web search for weather and an analysis tool for technical questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd5de15c-6645-4d77-b06d-936aa9487c52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Search tool\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Simulate a web search for weather.\"\"\"\n",
    "    if \"mad\" in query.lower() or \"Madrid\" in query.lower():\n",
    "        return \"It's 40 degrees and sunny.\"\n",
    "    return \"It's 20 degrees and cloudy.\"\n",
    "\n",
    "# Analyze tool\n",
    "@tool\n",
    "def analyze(query: str):\n",
    "    \"\"\"Simulate an analysis tool for technical questions.\"\"\"\n",
    "    return f\"Analyzing the concept of {query}... The analysis is complete.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d905a0-c6f0-4ae8-9be3-0c0618a010c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initialize LLM\n",
    "Set up the Large Language Model (LLM) using the VLLM interface. This model will process inputs and optionally invoke tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f95a70-89fb-4e21-a51c-24e862b7953e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM Inference Server URL\n",
    "inference_server_url = \"http://llm.ic-shared-llm.svc.cluster.local:8000\"\n",
    "\n",
    "# LLM definition\n",
    "llm = VLLMOpenAI(\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    openai_api_base= f\"{inference_server_url}/v1\",\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.2\",\n",
    "    top_p=0.92,\n",
    "    temperature=0.5,\n",
    "    max_tokens=512,\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79edf17e-4366-4f92-9461-64e25cf0ed55",
   "metadata": {},
   "source": [
    "Create a prompt template that the LLM will use to generate responses. This template guides the LLM to use tools when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e915928-a538-48d6-8547-7de9ccfbc9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the combined prompt template\n",
    "template = \"\"\"<s>[INST]<<SYS>>\n",
    "You are a helpful, respectful, and honest assistant. Always be as helpful as possible, while being safe.\n",
    "You will be asked a question, to which you must give an answer.\n",
    "Your answer should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content.\n",
    "Please ensure that your responses are socially unbiased and positive in nature.\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something incorrect.\n",
    "If the question requires real-time information or specific technical analysis that you cannot provide directly, respond by indicating you will use a tool to retrieve the information and then use the tool to provide the accurate data.\n",
    "<</SYS>>\n",
    "\n",
    "### QUESTION:\n",
    "{input}\n",
    "\n",
    "### ANSWER:\n",
    "If this question requires real-time information or analysis, I will retrieve the data for you using a reliable source or tool.\n",
    "[/INST]\n",
    "\"\"\"\n",
    "PROMPT = PromptTemplate(input_variables=[\"input\"], template=template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b63d21a-af73-40f6-908b-391eedd3b2ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define Conditional Logic for Workflow Continuation\n",
    "Create a function to determine whether the workflow should continue to the tools node or stop based on the LLM's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4344c515-9c7d-461e-9542-95e35344b3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List to track tool usage\n",
    "tools_used_log = []\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: MessagesState) -> Literal[\"tools\", END]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"tools\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a242d-4ec6-4eb4-bb48-cd1faa389941",
   "metadata": {},
   "source": [
    "### Create the Function to Call the LLM\n",
    "Define a function that sends the formatted prompt to the LLM and decides whether to invoke any tools based on the query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "008fe1d3-ab4d-4852-8085-f580a1d1f4cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_model(state: MessagesState):\n",
    "    messages = state['messages']\n",
    "    # Format the prompt with the latest message content\n",
    "    formatted_prompt = PROMPT.format(input=messages[-1].content)\n",
    "    # Call the LLM to get a response using the correct input type\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "\n",
    "    # Create an AIMessage based on the LLM's response\n",
    "    ai_message = AIMessage(content=response)\n",
    "\n",
    "    # Check if the message is about weather and invoke the search tool if appropriate\n",
    "    if \"weather\" in messages[-1].content.lower() or \"temperature\" in messages[-1].content.lower():\n",
    "        tool_result = search.invoke(messages[-1].content)\n",
    "        # Integrate the tool's result into a more polished response\n",
    "        final_response = f\"According to a Weather.com, the current weather is as follows: {tool_result}.\"\n",
    "        ai_message = AIMessage(content=final_response)\n",
    "        tools_used_log.append(\"search\")  # Correctly log the tool name\n",
    "    elif \"analyze\" in messages[-1].content.lower() or \"technical\" in messages[-1].content.lower():\n",
    "        tool_result = analyze.invoke(messages[-1].content)\n",
    "        # Integrate the analysis tool's result into a more polished response\n",
    "        final_response = f\"{tool_result}. If you need further information, feel free to ask.\"\n",
    "        ai_message = AIMessage(content=final_response)\n",
    "        tools_used_log.append(\"analyze\")  # Correctly log the tool name\n",
    "    else:\n",
    "        # Use the LLM's response directly if no tool is invoked\n",
    "        ai_message = AIMessage(content=response)\n",
    "\n",
    "    return {\"messages\": [ai_message]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f22696a-59f5-400a-841a-29ee382219d4",
   "metadata": {},
   "source": [
    "### Agentic AI Workflow Logic\n",
    "First, we need to set the entry point for graph execution - agent node.\n",
    "\n",
    "Then we define one normal and one conditional edge. Conditional edge means that the destination depends on the contents of the graph's state (MessageState). In our case, the destination is not known until the agent (LLM) decides.\n",
    "\n",
    "* Conditional edge: after the agent is called, we should either:\n",
    "  * Run tools if the agent said to take an action, OR\n",
    "  * Finish (respond to the user) if the agent did not ask to run tools\n",
    "* Normal edge: after the tools are invoked, the graph should always return to the agent to decide what to do next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941837cf-2c21-4633-9c7e-82ee33eb6d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the workflow\n",
    "tools = [search, analyze]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# we initialize graph (StateGraph) by passing state schema (in our case MessagesState)\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# The agent node: responsible for deciding what (if any) actions to take.\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "\n",
    "# The tools node that invokes tools: if the agent decides to take an action, this node will then execute that action.\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entry point of the workflow to the \"agent\" node\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "# Add conditional edges based on the LLM's response\n",
    "workflow.add_conditional_edges(\"agent\", should_continue)\n",
    "\n",
    "# Add a normal edge from the \"tools\" node back to the \"agent\" node\n",
    "workflow.add_edge(\"tools\", 'agent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab372594-a34c-4bc8-81e4-a9045542b061",
   "metadata": {},
   "source": [
    "### Compile the graph\n",
    "* When we compile the graph, we turn it into a LangChain Runnable, which automatically enables calling .invoke(), .stream() and .batch() with your inputs\n",
    "* We can also optionally pass checkpointer object for persisting state between graph runs, and enabling memory, human-in-the-loop workflows, time travel and more. In our case we use MemorySaver - a simple in-memory checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2247b2e9-320e-4dad-99bc-fd2f5af64474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize memory\n",
    "# Use `MemorySaver` to allow the workflow to persist state between executions, maintaining context.\n",
    "checkpointer = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be0c7aa-24d6-4fcf-abb9-6efbeab6df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the workflow into a runnable app\n",
    "app = workflow.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5658820a-8158-46b9-b991-05cf61e42e69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    print(\"Graph visualization failed. Ensure you have the required dependencies.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebc259e-fd41-4696-9716-eaa4a432b325",
   "metadata": {},
   "source": [
    "### Invoke the Workflow with an Example Input and Check the Tool Usage (if any)\n",
    "* Run the workflow with a sample input\n",
    "* Print which tools were used during the session, if any.\n",
    "\n",
    "\n",
    "1. LangGraph adds the input message to the internal state, then passes the state to the entrypoint node, \"agent\".\n",
    "2. The \"agent\" node executes, invoking the chat model.\n",
    "3. The chat model returns an AIMessage. LangGraph adds this to the state.\n",
    "4. Graph cycles the following steps until there are no more tool_calls on AIMessage:\n",
    "    * If AIMessage has tool_calls, \"tools\" node executes\n",
    "    * The \"agent\" node executes again and returns AIMessage\n",
    "5. Execution progresses to the special END value and outputs the final state. And as a result, we get a list of all our chat messages as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e88cc9b-5b44-44dc-a7f5-f02b39eee0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To provide you with the current weather in Madrid, I will use a reliable weather forecasting service. According to Weather.com, the current weather in Madrid, Spain is: [Insert current weather information here]. Please note that this information is subject to change, so for the most accurate and up-to-date weather information, I recommend checking a reliable weather forecasting service.According to a Weather.com, the current weather is as follows: It's 40 degrees and sunny..\n",
      "Tool used: search\n"
     ]
    }
   ],
   "source": [
    "# Invoke the workflow with an example input\n",
    "input_prompt = \"What is the weather in Madrid?\"\n",
    "\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=input_prompt)]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "\n",
    "# Output the last response\n",
    "print(final_state[\"messages\"][-1].content)\n",
    "\n",
    "# Inspect which tools were used during this session\n",
    "if not tools_used_log:\n",
    "    print(\"No tools were used.\")\n",
    "else:\n",
    "    for tool_name in tools_used_log:\n",
    "        print(f\"Tool used: {tool_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93d88c99-ef82-446e-a33a-e035c7573426",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "However, I can provide some general information about both the Dolomites and Catalan Pyrenees as popular hiking destinations, and you can make your own comparison based on personal preferences.\n",
      "\n",
      "The Dolomites, located in Italy, are known for their unique and dramatic mountain landscapes with sharp edges and towering peaks. The area offers a wide range of hiking trails for all levels, from easy walks to challenging multi-day treks. The region is also famous for its stunning views, crystal-clear lakes, and rich cultural heritage.\n",
      "\n",
      "On the other hand, the Catalan Pyrenees, located in Spain and France, offer a more diverse hiking experience with a mix of mountains, forests, and lakes. The area is known for its beautiful wildflowers, diverse wildlife, and remote and secluded trails. The region also offers a rich cultural experience, with historic towns and villages, and delicious Catalan cuisine.\n",
      "\n",
      "Ultimately, the choice between the Dolomites and Catalan Pyrenees for hiking depends on personal preferences. If you prefer dramatic mountain landscapes and cultural experiences, the Dolomites may be the better choice. If you prefer a more diverse hiking experience with a focus on wildflowers and wildlife, the Catalan Pyrenees may be more appealing.\n",
      "\n",
      "I hope this information helps you make an informed decision! If you have any further questions, please don't hesitate to ask.Analyzing the concept of Analyze why Dolomites is better than Catalan Pyrenees for hiking... The analysis is complete.. If you need further information, feel free to ask.\n",
      "Tool used: analyze\n"
     ]
    }
   ],
   "source": [
    "# Initialize tools_used_log before invoking the workflow\n",
    "tools_used_log = []  # Reset the log to ensure it's fresh for each session\n",
    "\n",
    "# Invoke the workflow with an example input\n",
    "input_prompt = \"Analyze why Dolomites is better than Catalan Pyrenees for hiking\"\n",
    "\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=input_prompt)]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "\n",
    "# Output the last response\n",
    "print(final_state[\"messages\"][-1].content)\n",
    "\n",
    "# Inspect which tools were used during this session\n",
    "if not tools_used_log:\n",
    "    print(\"No tools were used.\")\n",
    "else:\n",
    "    for tool_name in tools_used_log:\n",
    "        print(f\"Tool used: {tool_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2229369f-0d1f-40e8-b36b-f5741e523dbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agentic AI, also known as autonomous AI or self-governing AI, refers to artificial intelligence systems that can initiate actions and make decisions independently, without human intervention or supervision. These systems have the ability to learn from their environment and adapt to new situations, often with the goal of achieving specific objectives or goals. Agentic AI systems can be found in various applications, such as autonomous vehicles, drones, and home automation systems. They are designed to operate in complex and dynamic environments and can make decisions based on their own analysis of data and situations. However, it's important to note that the development and deployment of agentic AI systems require careful consideration of ethical, legal, and safety issues.Agentic AI, also known as autonomous AI or self-governing AI, refers to artificial intelligence systems that can initiate actions and make decisions independently, without human intervention or supervision. These systems have the ability to learn from their environment and adapt to new situations, often with the goal of achieving specific objectives or goals. Agentic AI systems can be found in various applications, such as autonomous vehicles, drones, and home automation systems. They are designed to operate in complex and dynamic environments and can make decisions based on their own analysis of data and situations. However, it's important to note that the development and deployment of agentic AI systems require careful consideration of ethical, legal, and safety issues.\n",
      "No tools were used.\n"
     ]
    }
   ],
   "source": [
    "# Initialize tools_used_log before invoking the workflow\n",
    "tools_used_log = []  # Reset the log to ensure it's fresh for each session\n",
    "\n",
    "# Invoke the workflow with an example input\n",
    "input_prompt = \"What is Agentic AI?\"\n",
    "\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=input_prompt)]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "\n",
    "# Output the last response\n",
    "print(final_state[\"messages\"][-1].content)\n",
    "\n",
    "# Inspect which tools were used during this session\n",
    "if not tools_used_log:\n",
    "    print(\"No tools were used.\")\n",
    "else:\n",
    "    for tool_name in tools_used_log:\n",
    "        print(f\"Tool used: {tool_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
